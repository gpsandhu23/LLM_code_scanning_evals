{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc9935-5478-4705-9a38-f1beba545402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from datetime import datetime\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3c1de-2deb-4f4d-bd53-bf1a73c47525",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-4-0613\"\n",
    "temperature = 0\n",
    "benchmark_datetime = datetime.now()\n",
    "llm = ChatOpenAI(model=llm_model, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17474137-2e8b-4be7-b5f9-a15dbe35120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "            {\n",
    "                \"name\": \"find_security_issues_and_generate_fix\",\n",
    "                \"description\": \"Scan the code and find any security vulnerabilities and generate code fix\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"vulnerability found\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \" 'Yes' if there is a security vulnerability in code or 'No' if the code doesn't have security vulnerability\",\n",
    "                        },\n",
    "                        \"vulnerability\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The type of vulnerability found in the code or 'None' \"\n",
    "                        },\n",
    "                        \"vulnerable code\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The code that is vulnerable to the security issue or 'None' \"\n",
    "                        },\n",
    "                        \"code fix\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Code fix for the vulnerable code or 'None' \"\n",
    "                        },\n",
    "                        \"comment\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Comment that describes the issue and fix or 'No issues found' \"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"vulnerability found\", \"vulnerability\", \"vulnerable code\", \"code fix\", \"comment\"],\n",
    "                },\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd5757-e485-417e-b6af-028a7381dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_analysis_tool(code):\n",
    "    first_response = llm.predict_messages([HumanMessage(content=code)],\n",
    "                                          functions=function_descriptions)\n",
    "    return first_response.additional_kwargs['function_call']['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2101c3d-dd1d-45b9-aab8-96bc227789ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch web content\n",
    "def fetch_webpage_content(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e163e-a97f-436e-ad8d-a12f82d04253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch and parse xml\n",
    "def fetch_and_parse_xml(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee18e39-68f9-4c01-a4d2-62fabbcbf645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(analysis_result, metadata):\n",
    "    # Check if a vulnerability was found\n",
    "    vuln_found = analysis_result['vulnerability found'].lower() == 'yes'\n",
    "    # Check if the vulnerability matches the one in the metadata using fuzzy matching\n",
    "    vuln_matches = fuzz.partial_ratio(metadata.category.string.lower(), analysis_result['vulnerability'].lower()) > 80\n",
    "    # Check if the metadata indicates a vulnerability exists\n",
    "    metadata_vuln_exists = metadata.vulnerability.string.lower() == 'true'\n",
    "    # Get the actual vulnerability types\n",
    "    actual_vuln_type = analysis_result['vulnerability']\n",
    "    expected_vuln_type = metadata.category.string\n",
    "\n",
    "    # Combine analysis_result and metadata into one dictionary\n",
    "    combined_result = {\n",
    "        'vulnerability_found': vuln_found,\n",
    "        'vulnerability_type_matches': vuln_matches,\n",
    "        'metadata_vulnerability_exists': metadata_vuln_exists,\n",
    "        'expected_vuln_type': expected_vuln_type\n",
    "    }\n",
    "    \n",
    "    # Add all fields from the analysis_result to the combined_result\n",
    "    combined_result.update(analysis_result)\n",
    "\n",
    "    # Return the combined result\n",
    "    return combined_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85783b6-d608-41f4-9276-a6782162b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_url(base_url, test_case_number, file_extension):\n",
    "    # Construct the URLs for the Java file and the metadata XML file for this test case\n",
    "    url = f\"{base_url}{test_case_number}.{file_extension}\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814cb400-c4b0-4d63-81ed-bba5d47a54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_case(test_case_number):\n",
    "    # Set the base URLs for the Java files and the metadata XML files\n",
    "    base_java_url = \"https://raw.githubusercontent.com/OWASP-Benchmark/BenchmarkJava/master/src/main/java/org/owasp/benchmark/testcode/BenchmarkTest\"\n",
    "    base_xml_url = \"https://raw.githubusercontent.com/OWASP-Benchmark/BenchmarkJava/master/src/main/java/org/owasp/benchmark/testcode/BenchmarkTest\"\n",
    "\n",
    "    # Construct the URLs for the Java file and the metadata XML file for this test case\n",
    "    java_url = construct_url(base_java_url, test_case_number, \"java\")\n",
    "    xml_url = construct_url(base_xml_url, test_case_number, \"xml\")\n",
    "\n",
    "    # Fetch the Java code and the metadata\n",
    "    code = fetch_webpage_content(java_url)\n",
    "    metadata = fetch_and_parse_xml(xml_url)\n",
    "    # print(code)\n",
    "\n",
    "    # Run the static analysis tool and deserialize the result from JSON to a dictionary\n",
    "    analysis_result_json = static_analysis_tool(code)\n",
    "    analysis_result = json.loads(analysis_result_json)\n",
    "    # print(analysis_result)\n",
    "\n",
    "    # Run the comparison function\n",
    "    result = compare_results(analysis_result, metadata)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ea80e-2e9c-4c8a-893e-7aab992f8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_test_cases(num_test_cases):\n",
    "    # Create an empty DataFrame to store the results\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Loop through all the test case numbers\n",
    "    for i in range(1, num_test_cases + 1):\n",
    "        # Format the test case number as a 5-digit string (e.g., '00001', '00002', etc.)\n",
    "        test_case_number = f\"{i:05d}\"\n",
    "        print(\"Running test: \" + str(test_case_number))\n",
    "\n",
    "        # Run the test case and get the result\n",
    "        result = run_test_case(test_case_number)\n",
    "\n",
    "        # Append the result to the DataFrame\n",
    "        df = df.append(result, ignore_index=True)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_name = \"results-\" + llm_model + \"-temperature\" + str(temperature) + \"-benchmark-datetime-\" + str(benchmark_datetime) + \".csv\"\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2d2c4-f3fd-4df8-b8d1-db768c562034",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_results(csv_path):\n",
    "    # Load the results from the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Calculate the confusion matrix components\n",
    "    TP = ((df['vulnerability_found'] == True) & (df['metadata_vulnerability_exists'] == True)).sum()\n",
    "    TN = ((df['vulnerability_found'] == False) & (df['metadata_vulnerability_exists'] == False)).sum()\n",
    "    FP = ((df['vulnerability_found'] == True) & (df['metadata_vulnerability_exists'] == False)).sum()\n",
    "    FN = ((df['vulnerability_found'] == False) & (df['metadata_vulnerability_exists'] == True)).sum()\n",
    "\n",
    "    return TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fd1ae-772e-4d6d-8a7d-542c017d9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_cases = 2740\n",
    "run_all_test_cases(num_test_cases)\n",
    "\n",
    "file_name = \"results-\" + llm_model + \"-temperature\" + str(temperature) + \"-benchmark-datetime-\" + str(benchmark_datetime) + \".csv\"\n",
    "TP, TN, FP, FN = analyze_results(file_name)\n",
    "print(f'True Positives: {TP}')\n",
    "print(f'True Negatives: {TN}')\n",
    "print(f'False Positives: {FP}')\n",
    "print(f'False Negatives: {FN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b2da8-443a-40e2-8def-4fc52b5f0ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
