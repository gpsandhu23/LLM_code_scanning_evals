# LLM code scanning evals

Set of tests to measure effectiveness of LLMs at identifying security issues in code and generating fixes
